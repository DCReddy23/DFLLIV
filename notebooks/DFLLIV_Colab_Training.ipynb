{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DCReddy23/DFLLIV/blob/main/notebooks/DFLLIV_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# DFLLIV - Low-Light Image Enhancement with Diffusion Fields\n",
    "\n",
    "This notebook provides a complete tutorial for training the DFLLIV model on Google Colab using the LOL dataset.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "- Set up the environment in Google Colab\n",
    "- Download and prepare the LOL dataset\n",
    "- Train a diffusion-based low-light enhancement model\n",
    "- Perform inference on test images\n",
    "- Evaluate model performance\n",
    "\n",
    "## üìã Requirements\n",
    "\n",
    "- Google Colab account (free tier works!)\n",
    "- Google Drive for dataset storage (~500MB) and checkpoints\n",
    "- GPU runtime (go to Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "\n",
    "## ‚è±Ô∏è Expected Training Time\n",
    "\n",
    "- With Colab T4 GPU: ~4-6 hours for 100 epochs\n",
    "- With Colab V100/A100: ~2-3 hours for 100 epochs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1Ô∏è‚É£ Setup: Check GPU and Mount Google Drive\n",
    "\n",
    "First, let's verify that we have a GPU available and mount Google Drive for persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create necessary directories in Google Drive\n",
    "!mkdir -p /content/drive/MyDrive/DFLLIV/checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/DFLLIV/runs\n",
    "!mkdir -p /content/drive/MyDrive/DFLLIV/outputs\n",
    "\n",
    "print(\"‚úì Google Drive mounted successfully\")\n",
    "print(\"‚úì Directories created in Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-header"
   },
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the DFLLIV repository\n",
    "import os\n",
    "if not os.path.exists('/content/DFLLIV'):\n",
    "    !git clone https://github.com/DCReddy23/DFLLIV.git /content/DFLLIV\n",
    "    print(\"‚úì Repository cloned\")\n",
    "else:\n",
    "    print(\"‚úì Repository already exists\")\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/DFLLIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies... This may take a few minutes.\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n‚úì All dependencies installed successfully!\")\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "import torchvision\n",
    "import yaml\n",
    "import lpips\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüì¶ Package versions:\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  TorchVision: {torchvision.__version__}\")\n",
    "print(f\"  CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-header"
   },
   "source": [
    "## 3Ô∏è‚É£ Download LOL Dataset\n",
    "\n",
    "The LOL (Low-Light) dataset contains 500 paired low-light and normal-light images.\n",
    "\n",
    "### Option A: Download from Google Drive (Recommended)\n",
    "\n",
    "Download the dataset from the official Google Drive link and upload to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset-gdrive"
   },
   "outputs": [],
   "source": [
    "# Download LOL dataset using gdown\n",
    "!pip install -q gdown\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Create data directory\n",
    "!mkdir -p /content/DFLLIV/data\n",
    "\n",
    "# Check if dataset already exists in Google Drive\n",
    "gdrive_dataset_path = \"/content/drive/MyDrive/DFLLIV/LOLdataset.zip\"\n",
    "local_dataset_path = \"/content/DFLLIV/data\"\n",
    "\n",
    "if os.path.exists(\"/content/DFLLIV/data/LOL\"):\n",
    "    print(\"‚úì LOL dataset already extracted!\")\n",
    "elif os.path.exists(gdrive_dataset_path):\n",
    "    print(\"Found dataset in Google Drive. Copying...\")\n",
    "    !cp \"{gdrive_dataset_path}\" /content/DFLLIV/data/\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile('/content/DFLLIV/data/LOLdataset.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/DFLLIV/data/')\n",
    "    \n",
    "    # Rename directory if needed\n",
    "    if os.path.exists('/content/DFLLIV/data/lol_dataset'):\n",
    "        !mv /content/DFLLIV/data/lol_dataset /content/DFLLIV/data/LOL\n",
    "    elif os.path.exists('/content/DFLLIV/data/LOLdataset'):\n",
    "        !mv /content/DFLLIV/data/LOLdataset /content/DFLLIV/data/LOL\n",
    "    \n",
    "    print(\"‚úì Dataset extracted successfully!\")\n",
    "else:\n",
    "    print(\"\"\"Dataset not found in Google Drive. Please download manually:\"\"\")\n",
    "    print(\"\"\"\\nüì• Manual Download Instructions:\"\"\")\n",
    "    print(\"\"\"1. Visit: https://drive.google.com/file/d/157bjO1_cFuSd0HWDUuAmcHRJDVyWpOxB/view\"\"\")\n",
    "    print(\"\"\"2. Download LOLdataset.zip\"\"\")\n",
    "    print(\"\"\"3. Upload to your Google Drive at: MyDrive/DFLLIV/LOLdataset.zip\"\"\")\n",
    "    print(\"\"\"4. Re-run this cell\"\"\")\n",
    "    print(\"\"\"\\nAlternatively, you can try direct download (may require manual intervention):\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-option-b"
   },
   "source": [
    "### Option B: Direct Download (if Option A doesn't work)\n",
    "\n",
    "Try downloading directly using gdown (may require authentication):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset-direct"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run if Option A doesn't work\n",
    "# Note: This may require you to authenticate with Google Drive\n",
    "\n",
    "# import gdown\n",
    "# import zipfile\n",
    "\n",
    "# if not os.path.exists('/content/DFLLIV/data/LOL'):\n",
    "#     print(\"Downloading LOL dataset...\")\n",
    "#     url = 'https://drive.google.com/uc?id=157bjO1_cFuSd0HWDUuAmcHRJDVyWpOxB'\n",
    "#     output = '/content/DFLLIV/data/LOLdataset.zip'\n",
    "#     gdown.download(url, output, quiet=False)\n",
    "    \n",
    "#     print(\"Extracting...\")\n",
    "#     with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('/content/DFLLIV/data/')\n",
    "    \n",
    "#     # Rename if needed\n",
    "#     if os.path.exists('/content/DFLLIV/data/lol_dataset'):\n",
    "#         !mv /content/DFLLIV/data/lol_dataset /content/DFLLIV/data/LOL\n",
    "#     elif os.path.exists('/content/DFLLIV/data/LOLdataset'):\n",
    "#         !mv /content/DFLLIV/data/LOLdataset /content/DFLLIV/data/LOL\n",
    "    \n",
    "#     print(\"‚úì Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-dataset"
   },
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "import os\n",
    "\n",
    "def verify_dataset():\n",
    "    base_path = '/content/DFLLIV/data/LOL'\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        print(\"‚ùå Dataset not found! Please download using instructions above.\")\n",
    "        return False\n",
    "    \n",
    "    train_low = os.path.join(base_path, 'our485', 'low')\n",
    "    train_high = os.path.join(base_path, 'our485', 'high')\n",
    "    test_low = os.path.join(base_path, 'eval15', 'low')\n",
    "    test_high = os.path.join(base_path, 'eval15', 'high')\n",
    "    \n",
    "    dirs = [train_low, train_high, test_low, test_high]\n",
    "    \n",
    "    print(\"üìÅ Dataset Structure:\")\n",
    "    for d in dirs:\n",
    "        if os.path.exists(d):\n",
    "            count = len([f for f in os.listdir(d) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            print(f\"  ‚úì {d}: {count} images\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {d}: NOT FOUND\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\n‚úì Dataset verification successful!\")\n",
    "    return True\n",
    "\n",
    "verify_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## 4Ô∏è‚É£ Load and Review Configuration\n",
    "\n",
    "We'll use a Colab-optimized configuration with:\n",
    "- Reduced batch size (4 instead of 8) for memory efficiency\n",
    "- Fewer epochs (100 instead of 500) for faster demo\n",
    "- Checkpoints saved to Google Drive for persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-config"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "# Load Colab configuration\n",
    "config_path = '/content/DFLLIV/configs/colab.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìù Colab Configuration:\")\n",
    "print(\"=\"*50)\n",
    "pprint(config)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüîß Key Settings:\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"  Learning Rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Validation Every: {config['training']['val_every']} epochs\")\n",
    "print(f\"  Save Every: {config['training']['save_every']} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "optional-config"
   },
   "source": [
    "### Optional: Adjust Configuration\n",
    "\n",
    "You can modify the configuration if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "modify-config"
   },
   "outputs": [],
   "source": [
    "# Optional: Reduce epochs further for quick testing\n",
    "# config['training']['num_epochs'] = 20\n",
    "# config['training']['val_every'] = 5\n",
    "\n",
    "# Optional: Change batch size based on your GPU\n",
    "# config['training']['batch_size'] = 2  # For lower memory\n",
    "# config['training']['batch_size'] = 8  # For higher memory GPUs\n",
    "\n",
    "# Save modified config\n",
    "# with open(config_path, 'w') as f:\n",
    "#     yaml.dump(config, f)\n",
    "# print(\"‚úì Configuration updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-header"
   },
   "source": [
    "## 5Ô∏è‚É£ Start Training\n",
    "\n",
    "Now we'll start the training process. This will:\n",
    "- Train the diffusion field model on the LOL dataset\n",
    "- Save checkpoints to Google Drive every 25 epochs\n",
    "- Validate every 5 epochs\n",
    "- Display training progress\n",
    "\n",
    "**Note:** Training 100 epochs on Colab T4 GPU takes approximately 4-6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start-training"
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python train.py --config configs/colab.yaml\n",
    "\n",
    "# Note: If training is interrupted, you can resume with:\n",
    "# !python train.py --config configs/colab.yaml --resume /content/drive/MyDrive/DFLLIV/checkpoints/latest.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor-header"
   },
   "source": [
    "## 6Ô∏è‚É£ Monitor Training Progress\n",
    "\n",
    "While training is running, you can monitor progress using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard\n",
    "%tensorboard --logdir /content/drive/MyDrive/DFLLIV/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-header"
   },
   "source": [
    "### Visualize Training Samples\n",
    "\n",
    "Check the training visualizations saved during validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-training-vis"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Find training visualization images\n",
    "vis_files = sorted(glob.glob('/content/DFLLIV/outputs/train_vis/*.png'))\n",
    "\n",
    "if vis_files:\n",
    "    print(f\"Found {len(vis_files)} training visualization images\\n\")\n",
    "    \n",
    "    # Show the latest few\n",
    "    for img_path in vis_files[-3:]:\n",
    "        img = Image.open(img_path)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(img_path.split('/')[-1])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No training visualizations found yet. These will appear during validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference-header"
   },
   "source": [
    "## 7Ô∏è‚É£ Inference on Test Images\n",
    "\n",
    "After training (or using a checkpoint), let's test the model on some low-light images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "single-inference"
   },
   "outputs": [],
   "source": [
    "# Find the best checkpoint\n",
    "checkpoint_path = '/content/drive/MyDrive/DFLLIV/checkpoints/best.pth'\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    # Use latest if best doesn't exist\n",
    "    checkpoint_path = '/content/drive/MyDrive/DFLLIV/checkpoints/latest.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"‚úì Using checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Get a test image\n",
    "    test_image = glob.glob('/content/DFLLIV/data/LOL/eval15/low/*.png')[0]\n",
    "    output_path = '/content/drive/MyDrive/DFLLIV/outputs/enhanced_test.png'\n",
    "    \n",
    "    print(f\"\\nEnhancing: {test_image}\")\n",
    "    \n",
    "    # Run inference\n",
    "    !python inference.py \\\n",
    "        --checkpoint {checkpoint_path} \\\n",
    "        --input {test_image} \\\n",
    "        --output {output_path} \\\n",
    "        --num-steps 50 \\\n",
    "        --sampling-method ddim\n",
    "    \n",
    "    # Display result\n",
    "    if os.path.exists(output_path):\n",
    "        img = Image.open(output_path)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Low-Light Input vs Enhanced Output')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found. Please train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-inference-header"
   },
   "source": [
    "### Batch Inference on All Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-inference"
   },
   "outputs": [],
   "source": [
    "# Process all test images\n",
    "if os.path.exists(checkpoint_path):\n",
    "    test_dir = '/content/DFLLIV/data/LOL/eval15/low'\n",
    "    output_dir = '/content/drive/MyDrive/DFLLIV/outputs/test_results'\n",
    "    \n",
    "    print(\"Enhancing all test images...\")\n",
    "    !python inference.py \\\n",
    "        --checkpoint {checkpoint_path} \\\n",
    "        --input {test_dir} \\\n",
    "        --output {output_dir} \\\n",
    "        --num-steps 50 \\\n",
    "        --sampling-method ddim\n",
    "    \n",
    "    print(\"\\n‚úì Done! Results saved to Google Drive\")\n",
    "    print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation-header"
   },
   "source": [
    "## 8Ô∏è‚É£ Evaluate Model Performance\n",
    "\n",
    "Compute PSNR, SSIM, and LPIPS metrics on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "if os.path.exists(checkpoint_path):\n",
    "    eval_output_dir = '/content/drive/MyDrive/DFLLIV/outputs/evaluation'\n",
    "    \n",
    "    !python evaluate.py \\\n",
    "        --checkpoint {checkpoint_path} \\\n",
    "        --dataset-dir /content/DFLLIV/data/LOL/eval15 \\\n",
    "        --output-dir {eval_output_dir} \\\n",
    "        --num-steps 50\n",
    "    \n",
    "    # Display metrics\n",
    "    import json\n",
    "    metrics_file = os.path.join(eval_output_dir, 'metrics.json')\n",
    "    \n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(\"\\nüìä Evaluation Results:\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"PSNR:  {metrics['psnr']:.2f} ¬± {metrics['psnr_std']:.2f} dB\")\n",
    "        print(f\"SSIM:  {metrics['ssim']:.4f} ¬± {metrics['ssim_std']:.4f}\")\n",
    "        print(f\"LPIPS: {metrics['lpips']:.4f} ¬± {metrics['lpips_std']:.4f}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    # Show comparison grid\n",
    "    grid_path = os.path.join(eval_output_dir, 'comparison_grid.png')\n",
    "    if os.path.exists(grid_path):\n",
    "        img = Image.open(grid_path)\n",
    "        plt.figure(figsize=(20, 15))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Comparison Grid: Input vs Enhanced vs Ground Truth')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 9Ô∏è‚É£ Download Results\n",
    "\n",
    "All checkpoints and results are saved to your Google Drive at:\n",
    "- Checkpoints: `MyDrive/DFLLIV/checkpoints/`\n",
    "- Logs: `MyDrive/DFLLIV/runs/`\n",
    "- Outputs: `MyDrive/DFLLIV/outputs/`\n",
    "\n",
    "You can also download specific files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-files"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download best checkpoint\n",
    "checkpoint_path = '/content/drive/MyDrive/DFLLIV/checkpoints/best.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Downloading best checkpoint...\")\n",
    "    # files.download(checkpoint_path)  # Uncomment to download\n",
    "    print(\"Note: Large file - recommend accessing from Google Drive\")\n",
    "else:\n",
    "    print(\"No checkpoint found\")\n",
    "\n",
    "# List all available checkpoints\n",
    "print(\"\\nüì¶ Available checkpoints in Google Drive:\")\n",
    "!ls -lh /content/drive/MyDrive/DFLLIV/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips-header"
   },
   "source": [
    "## üí° Tips and Troubleshooting\n",
    "\n",
    "### Training Tips\n",
    "\n",
    "1. **Out of Memory Errors**:\n",
    "   - Reduce batch size to 2 or 1\n",
    "   - Reduce `crop_size` in config to 128\n",
    "\n",
    "2. **Speed Up Training**:\n",
    "   - Use fewer epochs for quick testing (e.g., 20-50)\n",
    "   - Reduce validation frequency\n",
    "\n",
    "3. **Session Timeout**:\n",
    "   - Colab free tier disconnects after ~12 hours\n",
    "   - Resume training with: `--resume /content/drive/MyDrive/DFLLIV/checkpoints/latest.pth`\n",
    "\n",
    "4. **Better Results**:\n",
    "   - Train for more epochs (200-500)\n",
    "   - Use higher batch size if GPU allows (8 or 16)\n",
    "   - Try the UNet architecture: Change `model.type` to `\"unet\"` in config\n",
    "\n",
    "### Quick Test Run\n",
    "\n",
    "For a quick test (5-10 minutes), modify config:\n",
    "```python\n",
    "config['training']['num_epochs'] = 5\n",
    "config['training']['val_every'] = 1\n",
    "```\n",
    "\n",
    "### Useful Commands\n",
    "\n",
    "```bash\n",
    "# Resume training\n",
    "!python train.py --config configs/colab.yaml --resume /content/drive/MyDrive/DFLLIV/checkpoints/latest.pth\n",
    "\n",
    "# Quick inference\n",
    "!python inference.py --checkpoint /content/drive/MyDrive/DFLLIV/checkpoints/best.pth --input test.jpg --output enhanced.png\n",
    "\n",
    "# Evaluate specific checkpoint\n",
    "!python evaluate.py --checkpoint /content/drive/MyDrive/DFLLIV/checkpoints/checkpoint_epoch_50.pth --dataset-dir data/LOL/eval15 --output-dir results\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/DCReddy23/DFLLIV)\n",
    "- [Project README](https://github.com/DCReddy23/DFLLIV/blob/main/README.md)\n",
    "- [LOL Dataset Paper](https://arxiv.org/abs/1808.04560)\n",
    "\n",
    "## üôè Acknowledgments\n",
    "\n",
    "- DDPM/DDIM for diffusion models\n",
    "- NeRF for neural field inspiration\n",
    "- LOL dataset by Wei et al.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
